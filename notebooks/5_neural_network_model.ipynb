{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch CNN for image classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch nightly view was used in the project due to the lack of support for apple silicon of the regular version.\n",
    "download link: https://pytorch.org/get-started/locally/\n",
    "- MPS acceleration is available on MacOS 12.3+\n",
    "- pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "The project requires training data to be launched, which should be in the `data/train_set/*` folder, the data can be downloaded from [ING Challenge Rocket](https://challengerocket.com/hacking/resources#go-pagecontent)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pytesseract\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check Apple Silicon architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upload training files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_folder = os.path.join('..', 'data', 'train_set')\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for folder_name in os.listdir(main_folder):\n",
    "    folder_path = os.path.join(main_folder, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        image_files = glob.glob(os.path.join(folder_path, '*.tiff'))\n",
    "\n",
    "        image_paths.extend(image_files)\n",
    "        labels.extend([folder_name] * len(image_files))\n",
    "\n",
    "train_source_df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "\n",
    "source_df = train_source_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    \"advertisement\": 0,\n",
    "    \"budget\": 1,\n",
    "    \"email\": 2,\n",
    "    \"file_folder\": 3,\n",
    "    \"form_folder\": 3,\n",
    "    \"form\": 4,\n",
    "    \"handwritten\": 5,\n",
    "    \"invoice\": 6,\n",
    "    \"letter\": 7,\n",
    "    \"memo\": 8,\n",
    "    \"news_article\": 9,\n",
    "    \"news_report\": 9,\n",
    "    \"pit37_v1\": 10,\n",
    "    \"pozwolenie_uzytkowanie_obiektu_budowlanego\": 11,\n",
    "    \"presentation\": 12,\n",
    "    \"questionnaire\": 13,\n",
    "    \"resume\": 14,\n",
    "    \"scientific_publication\": 15,\n",
    "    \"scientific_report\": 16,\n",
    "    \"scientific_raport\": 16,\n",
    "    \"specification\": 17,\n",
    "    \"umowa_na_odleglosc_odstapienie\": 18,\n",
    "    \"umowa_o_dzielo\": 19,\n",
    "    \"umowa_sprzedazy_samochodu\": 20\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source_df['label'] = source_df['label'].apply(lambda x: labels_dict[x])\n",
    "source_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define custom dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform_=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.data.iloc[index]['image_path']\n",
    "        label = self.data.iloc[index]['label']\n",
    "\n",
    "        image = Image.open(image_path).convert('L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define two-layered CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    num_classes = 21\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.fc = nn.Linear(119072, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = CustomDataset(source_df, transform_=transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MyCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {running_loss / 10:.4f}')\n",
    "            running_loss = 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on the test set: {accuracy * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join('..', 'models', 'model.pth'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()\n",
    "\n",
    "model_cnn = MyCNN()\n",
    "model_cnn.load_state_dict(model_state_dict)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_model = os.path.join(\"..\", \"models\", \"vectorizer.pkl\")\n",
    "with open(path_model, 'wb') as file:\n",
    "    tfidf_fitted = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction pipeline\n",
    "If probability of prediction from Logistic Regression is over 0.9, the result is returned. Otherwise, the object is pipelined to CNN and a new prediction is returned."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    file_path = input(\"Path to file to class predict: \")\n",
    "\n",
    "    try:\n",
    "        image_ = Image.open(file_path)\n",
    "    except Exception as error:\n",
    "        print(\"Error while reading the file:\", str(error))\n",
    "\n",
    "    ocr_result = pytesseract.image_to_string(image_, lang='eng+pol')\n",
    "\n",
    "    vect_text = tfidf_fitted.transform([ocr_result])\n",
    "    probabilites = model.predict_proba(vect_text)\n",
    "\n",
    "    probabilites_index = probabilites.argmax()\n",
    "    if probabilites[0][probabilites_index] > 0.9:\n",
    "        return probabilites_index\n",
    "    else:\n",
    "        img = Image.open(file_path).convert('L')\n",
    "        img = transform(img).unsqueeze(0)\n",
    "\n",
    "        model_cnn.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model_cnn(img)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "        predicted_label = predicted.item()\n",
    "        return predicted_label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = [*labels_dict.values()].index(run_pipeline())\n",
    "print([*labels_dict.keys()][idx])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
